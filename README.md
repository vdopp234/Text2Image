# Text2Image

This project uses the StackGAN Architecture, as described in the linked paper, to create a model which given a text input can generate a 256x256 image. 

I used the Tensorflow, Keras, and Numpy libraries for Python to implement this model, and I trained my model using the Caltech/UCSD Birds Dataset. My model can be generalized to generate images other than birds by instead using the MS COCO dataset.  

Note: This repository does NOT include the dataset used to train the model, as it took an extraordinarily long time to push the data. Instead, I will leave a link to the dataset below. 

Paper: https://arxiv.org/pdf/1612.03242.pdf
Dataset: http://www.vision.caltech.edu/visipedia/CUB-200-2011.html
